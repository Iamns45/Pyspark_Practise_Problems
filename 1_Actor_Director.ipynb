{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5-5MK7pux4-",
        "outputId": "df004d94-832c-4914-982c-7dd7cbbd37b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Using cached pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488490 sha256=b717cf84e20ce8a7f46e28bcebedc6578ede1c0cff92474ed964d4d81527e6d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col,count"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder.appName(\"Create DataFrame Example\").getOrCreate()\n",
        "\n",
        "# Define the data from the image\n",
        "data = [\n",
        "    (1, 1, 0),\n",
        "    (1, 1, 1),\n",
        "    (1, 1, 2),\n",
        "    (1, 2, 3),\n",
        "    (1, 2, 4),\n",
        "    (2, 1, 5),\n",
        "    (2, 1, 6)\n",
        "]\n",
        "\n",
        "# Define the schema\n",
        "columns = [\"ACTOR_ID\", \"DIRECTOR_ID\", \"TIMESTAMP\"]\n",
        "\n",
        "# Create DataFrame\n",
        "input_df = spark.createDataFrame(data, schema=columns)\n",
        "\n",
        "# Show the DataFrame\n",
        "input_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GqSige7vGt0",
        "outputId": "47aa0ab5-cc78-4c8e-98e8-93f60cc12b5d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------+---------+\n",
            "|ACTOR_ID|DIRECTOR_ID|TIMESTAMP|\n",
            "+--------+-----------+---------+\n",
            "|       1|          1|        0|\n",
            "|       1|          1|        1|\n",
            "|       1|          1|        2|\n",
            "|       1|          2|        3|\n",
            "|       1|          2|        4|\n",
            "|       2|          1|        5|\n",
            "|       2|          1|        6|\n",
            "+--------+-----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Actors has cooperated with the Directors atleast 3 times\n",
        "grouped_df = input_df.groupBy([\"ACTOR_ID\",\"DIRECTOR_ID\"]).agg(count(\"TIMESTAMP\").alias(\"combination\"))\n",
        "grouped_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_IPNxTSvh-8",
        "outputId": "0f9603f7-e15f-4b27-ea6a-6f6c6e24d09a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------+-----------+\n",
            "|ACTOR_ID|DIRECTOR_ID|combination|\n",
            "+--------+-----------+-----------+\n",
            "|       1|          1|          3|\n",
            "|       1|          2|          2|\n",
            "|       2|          1|          2|\n",
            "+--------+-----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_df.select(\"ACTOR_ID\",\"DIRECTOR_ID\").filter(grouped_df.combination >= 3).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYP-tERDwMHW",
        "outputId": "83c7d36c-eb5c-4a48-dadd-b72066451696"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------+\n",
            "|ACTOR_ID|DIRECTOR_ID|\n",
            "+--------+-----------+\n",
            "|       1|          1|\n",
            "+--------+-----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}